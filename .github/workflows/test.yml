name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 6 AM UTC
    - cron: '0 6 * * *'

jobs:
  # Unit and Integration Tests
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.8', '3.9', '3.10', '3.11']
        exclude:
          # Reduce matrix size for faster CI
          - os: windows-latest
            python-version: '3.8'
          - os: macos-latest
            python-version: '3.8'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov pytest-asyncio pytest-timeout
        pip install -r requirements.txt
    
    - name: Create test directories
      run: |
        mkdir -p config models logs data
    
    - name: Run unit tests
      run: |
        pytest tests/ -m "unit" --cov=src --cov-report=xml --cov-report=term-missing -v
    
    - name: Run integration tests (without AI models)
      run: |
        pytest tests/ -m "integration and not ai_models" --cov=src --cov-append --cov-report=xml -v
    
    - name: Upload coverage to Codecov
      if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.10'
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  # GUI Tests (Linux only with virtual display)
  gui-tests:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y xvfb python3-tk
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-timeout
        pip install -r requirements.txt
    
    - name: Run GUI tests with virtual display
      run: |
        xvfb-run -a pytest tests/ -m "gui" -v --timeout=60
  
  # AI Model Tests (separate job due to size)
  ai-model-tests:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[test-models]')
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Cache AI models
      uses: actions/cache@v3
      with:
        path: models/
        key: ${{ runner.os }}-models-${{ hashFiles('src/model_manager.py') }}
        restore-keys: |
          ${{ runner.os }}-models-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-timeout
        pip install -r requirements.txt
    
    - name: Download test models (small versions)
      run: |
        python -c "
        from src.model_manager import ModelManager
        manager = ModelManager()
        try:
            manager.download_default_models(['toxicity_detector'])
        except Exception as e:
            print(f'Model download failed: {e}')
            print('Continuing with mocked models...')
        "
    
    - name: Run AI model integration tests
      run: |
        pytest tests/ -m "ai_models" -v --timeout=300

  # Security and Code Quality
  security:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety
    
    - name: Run Bandit security scanner
      run: |
        bandit -r src/ -f json -o bandit-report.json || true
        bandit -r src/ -f txt
    
    - name: Check for known vulnerabilities
      run: |
        safety check --json --output safety-report.json || true
        safety check
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  # Performance Tests
  performance:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-benchmark
        pip install -r requirements.txt
    
    - name: Run performance tests
      run: |
        pytest tests/ -k "performance" --benchmark-only --benchmark-json=benchmark.json -v
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: benchmark.json

  # Code Style and Linting
  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install linting tools
      run: |
        python -m pip install --upgrade pip
        pip install black flake8 isort mypy
        pip install -r requirements.txt
    
    - name: Check code formatting with Black
      run: |
        black --check --diff src/ tests/
    
    - name: Check import sorting with isort
      run: |
        isort --check-only --diff src/ tests/
    
    - name: Lint with flake8
      run: |
        flake8 src/ tests/ --max-line-length=100 --extend-ignore=E203,W503
    
    - name: Type check with mypy
      run: |
        mypy src/ --ignore-missing-imports --no-strict-optional

  # Test Summary and Reporting
  test-summary:
    needs: [test, gui-tests, security, performance, lint]
    runs-on: ubuntu-latest
    if: always()
    steps:
    - name: Test Summary
      run: |
        echo "## Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Test Type | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| Unit & Integration | ${{ needs.test.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| GUI Tests | ${{ needs.gui-tests.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Security Scan | ${{ needs.security.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Performance Tests | ${{ needs.performance.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Code Quality | ${{ needs.lint.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ needs.test.result }}" == "success" && 
              "${{ needs.gui-tests.result }}" == "success" && 
              "${{ needs.security.result }}" == "success" && 
              "${{ needs.lint.result }}" == "success" ]]; then
          echo "✅ All critical tests passed!" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Some tests failed. Please check the details above." >> $GITHUB_STEP_SUMMARY
        fi